# ðŸŸ¡ Email: Re: [openai/openai-python] Feature Request: Add HTTP/2 Support for High-Concurrency Workloads (Issue #2726)

## Metadata
- **Source:** Gmail
- **From:** HavenCTO <notifications@github.com>
- **Date:** Sun, 18 Jan 2026 10:47:29 -0800
- **Importance:** MEDIUM
- **Message ID:** 19bd26f05749f1c8
- **Created:** 2026-01-19T22:58:48.210292
- **Sender Reputation:** github.com

---

## Summary
HavenCTO left a comment (openai/openai-python#2726) @fede-kamel I also have a high performance use case and create multiplexer-llm as a wrapper for the async openai client https://github.com/Haven-hvn/

---

## Full Content
HavenCTO left a comment (openai/openai-python#2726)

@fede-kamel  I also have a high performance use case and create multiplexer-llm as a wrapper for the async openai client https://github.com/Haven-hvn/multiplexer-llm 

I will be adding http2 by passing a custom httpx client as Kar described, please review and provide feedback, thanks

-- 
Reply to this email directly or view it on GitHub:
https://github.com/openai/openai-python/issues/2726#issuecomment-3765597874
You are receiving this because you are subscribed to this thread.

Message ID: <openai/openai-python/issues/2726/3765597874@github.com>

---

## Suggested Actions
- [ ] Read and understand the email
- [ ] Determine if response is needed
- [ ] Draft response (if applicable)
- [ ] Archive or follow up

---

## Decision Required
- [ ] **No action needed** - Archive this email
- [ ] **Reply needed** - Draft response for approval
- [ ] **Forward to human** - Requires human attention
- [ ] **Schedule follow-up** - Set reminder for later

---

## Notes
_Add any notes or context here_

